{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc24eed8-845c-4f6c-a8a2-32d5858a10b8",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e1dfd-202d-49af-a358-43877a5634e2",
   "metadata": {},
   "source": [
    "#### Step-by-Step Process Before PCA\n",
    "\n",
    "Below is a structured sequence of steps to follow before deciding whether PCA should be applied to your dataset. I am keeping all the details intact from my earlier explanation, and this time I am also adding a list of plots you can make at relevant steps, along with what they can help you discover.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 1. **Understand the Data and Features**\n",
    "- Carefully read through your dataset and understand what each column represents (which you’ve already started doing — e.g., GDP per capita, education expenditure, healthcare expenditure, unemployment rate, crime rate).\n",
    "- Clarify whether each column is measured at a national level (macro indicators) or at a regional/city/state level.\n",
    "- Check if features are measured in the same unit (like USD vs. INR, or percentages vs. absolute values).  \n",
    "\n",
    "**Plots to make**  \n",
    "- *Bar chart or pie chart*: to visualize the proportion of spending categories (like education vs. health) if data is in percentages.  \n",
    "- *Line plots*: to see how indicators like GDP, education spending, healthcare spending have changed over time.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2. **Check Data Quality**\n",
    "- Look for missing values, duplicated rows, inconsistent formatting.  \n",
    "- For numerical columns, check if extreme outliers exist.  \n",
    "\n",
    "**Plots to make**  \n",
    "- *Histogram*: to view distribution of each feature and spot skewness.  \n",
    "- *Boxplot*: to detect outliers for each feature.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3. **Check Scale of Variables**\n",
    "- PCA is very sensitive to scale because it uses variance. A feature with very large values (like GDP in trillions) can dominate features with smaller values (like unemployment rate in percentage).\n",
    "- For example, GDP per capita could be in thousands, education expenditure per capita in hundreds, and unemployment in single digits. If left unscaled, GDP will heavily dominate the PCA.  \n",
    "- Therefore, **standardization (z-score scaling)** is almost always done before PCA (mean = 0, std = 1 for each feature).  \n",
    "- If some features are ratios/percentages, they’re already comparable, but it’s still best practice to standardize everything together.  \n",
    "\n",
    "**Plots to make**  \n",
    "- *Density plots (before and after scaling)*: to confirm features are now on comparable scales.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Step 4. **Check Multicollinearity Between Features**\n",
    "- PCA shines when features are correlated/redundant. If most features are independent, PCA won’t add much value.  \n",
    "- Compute the correlation matrix. Look for groups of features with high correlation (positive or negative).  \n",
    "- Example: Education expenditure per capita and healthcare expenditure per capita may move together because both are parts of government spending.  \n",
    "\n",
    "**Plots to make**  \n",
    "- *Heatmap of correlation matrix*: to visualize correlation patterns among features.  \n",
    "- *Pairplot (scatterplot matrix)*: to visually see relationships between features.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Step 5. **Suitability for PCA**\n",
    "- Not all datasets are appropriate for PCA.  \n",
    "- Statistical checks:  \n",
    "  - **KMO (Kaiser-Meyer-Olkin) test** → measures sampling adequacy. Higher (>0.6) means PCA likely useful.  \n",
    "  - **Bartlett’s test of sphericity** → checks whether correlation matrix is significantly different from identity matrix. Significant result means PCA makes sense.  \n",
    "- These tests basically confirm that your dataset has redundancy/overlap and PCA can meaningfully reduce dimensions.  \n",
    "\n",
    "**Plots to make**  \n",
    "- *Scree plot*: to check eigenvalues (important later, but useful for suitability too).  \n",
    "\n",
    "---\n",
    "\n",
    "#### Step 6. **Decide Your Goal**\n",
    "- Think clearly why you want PCA.  \n",
    "  - Do you want to reduce the dataset from 6–7 indicators into 2–3 combined indices (like “economic strength index”, “social well-being index”)?  \n",
    "  - Or do you want to use PCA just as preprocessing before clustering/ML?  \n",
    "- Having this goal in mind helps you interpret the principal components later.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Step 7. **Run PCA and Analyze Variance Explained**\n",
    "- When you run PCA, check the eigenvalues and variance explained by each component.  \n",
    "- Typically, first few components explain most of the variance.  \n",
    "- Use a **scree plot** (elbow method) to decide how many PCs to retain.  \n",
    "\n",
    "**Plots to make**  \n",
    "- *Scree plot*: shows how much variance each component explains.  \n",
    "- *Cumulative variance plot*: to see how many components together capture 80–90% of variance.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Step 8. **Interpret the Components**\n",
    "- Look at the loadings (coefficients of each original feature in the principal components).  \n",
    "- Try to interpret them meaningfully. Example:  \n",
    "  - PC1 may load heavily on GDP, education, and healthcare → representing “economic development”.  \n",
    "  - PC2 may load heavily on unemployment and crime → representing “social stress”.  \n",
    "- These interpretations help you understand underlying dimensions that drive the dataset.  \n",
    "\n",
    "**Plots to make**  \n",
    "- *Biplot (PC1 vs PC2 with loadings)*: shows both data points and how features contribute.  \n",
    "- *Component loading heatmap*: to see which variables strongly influence each component.  \n",
    "- *Scatter plot of first two PCs*: to observe clusters or patterns in reduced space.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Summary\n",
    "The general workflow before PCA:  \n",
    "1. Understand dataset and units  \n",
    "2. Check data quality  \n",
    "3. Standardize/scale features  \n",
    "4. Check correlations (redundancy)  \n",
    "5. Test suitability for PCA (KMO, Bartlett)  \n",
    "6. Clarify your analysis goal  \n",
    "7. Run PCA and study variance explained  \n",
    "8. Interpret principal components  \n",
    "\n",
    "With these steps and the suggested plots, you’ll be able to both validate whether PCA is appropriate and also extract meaningful insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ef44cf-832c-44d2-b941-2e447b61af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f109f6-7563-473d-bdbb-31acc2e923cf",
   "metadata": {},
   "source": [
    "I have a word file with 3 dataset tables.<br>\n",
    "I will be extracting those tables using <code><b>docx</b></code> library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e836523e-7f5f-49fe-8dc5-79fb8fa72dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data,\n",
    "doc = Document('data/pca_datasets.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e2273-b7c0-4f3c-9527-e092603e933f",
   "metadata": {},
   "source": [
    "##### Step 1: Extract Table from MS-Word and create pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "744ae8df-47c9-4c1a-9bff-29765bde56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the first table\n",
    "table1 = doc.tables[0]\n",
    "#Dictionary to store each table-column as one entry \n",
    "data_table={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d290ccb9-d95f-4fb1-88fb-c3f7b1de9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary with column-header as key and remaining data in that column as list-of-values.\n",
    "#e.g. {\"Region\":\"['A', 'B',...]\", \"GDP\":\"[5.3, 2.2,...]\"}\n",
    "for column in table1.columns:\n",
    "    col = [cell.text.strip().replace('\\n', ' ') for cell in column.cells]\n",
    "    data_table[col[0]] = col[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b39a895c-2e63-4973-9bdf-e4b9d854b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534bd787-9d08-496d-adc0-f43c648eb583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                   Non-Null Count  Dtype \n",
      "---  ------                                   --------------  ----- \n",
      " 0   Region                                   10 non-null     object\n",
      " 1   GDP per capita (USD)                     10 non-null     object\n",
      " 2   Unemployment Rate (%)                    10 non-null     object\n",
      " 3   Education Expenditure per capita (USD)   10 non-null     object\n",
      " 4   Healthcare Expenditure per capita (USD)  10 non-null     object\n",
      " 5   Crime Rate (per 1000 inhabitants)        10 non-null     object\n",
      "dtypes: object(6)\n",
      "memory usage: 612.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07260c29-1a88-4522-a5ad-80645fd6dc15",
   "metadata": {},
   "source": [
    "In the code below, the column-names are being simplied for easier handling.  \n",
    "The original & new name are present in table below:\n",
    "<table style=\"border:2px solid black;\">\n",
    "    <tr style=\"border:1px solid black;\">\n",
    "        <th style=\"border:1px solid black;\">Original colname</th>\n",
    "        <th style=\"border:1px solid black;\">New colname</th>\n",
    "    </tr>\n",
    "    <tr style=\"border:1px solid black;\">\n",
    "        <td style=\"border:1px solid black;\">Region</td>\n",
    "        <td style=\"border:1px solid black;\">region</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:1px solid black;\">\n",
    "        <td style=\"border:1px solid black;\">GDP per capita (USD)</td>\n",
    "        <td style=\"border:1px solid black;\">gdp</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:1px solid black;\">\n",
    "        <td style=\"border:1px solid black;\">Unemployment Rate(%)</td>\n",
    "        <td style=\"border:1px solid black;\">umemploy_rate</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:1px solid black;\">\n",
    "        <td style=\"border:1px solid black;\">Education Expenditure per capita (USD)</td>\n",
    "        <td style=\"border:1px solid black;\">ed_expend</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:1px solid black;\">\n",
    "        <td style=\"border:1px solid black;\">Healthcare Expenditure per capita (USD)</td>\n",
    "        <td style=\"border:1px solid black;\">health_expend</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:1px solid black;\">\n",
    "        <td style=\"border:1px solid black;\">Crime Rate (per 1000 inhabitants)</td>\n",
    "        <td style=\"border:1px solid black;\">crime_rate</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696dd0fb-48ef-40d6-bc2b-3770204d8df8",
   "metadata": {},
   "source": [
    "##### Step 2: Clean dataframe and view feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03abea94-6da6-4065-a4ed-117ca1e9f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df.rename(columns={\"Region\":\"region\", \"GDP per capita (USD)\":\"gdp\", \n",
    "                   \"Unemployment Rate (%)\":\"unemploy_rate\", \n",
    "                   \"Education Expenditure per capita (USD)\":\"ed_expend\",\n",
    "                  \"Healthcare Expenditure per capita (USD)\":\"health_expend\",\n",
    "                  \"Crime Rate (per 1000 inhabitants)\":\"crime_rate\"},\n",
    "         inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cabc3de-d5df-439d-a745-ddf91fac4588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>gdp</th>\n",
       "      <th>unemploy_rate</th>\n",
       "      <th>ed_expend</th>\n",
       "      <th>health_expend</th>\n",
       "      <th>crime_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>25000</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>22000</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "      <td>1800</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>28000</td>\n",
       "      <td>4</td>\n",
       "      <td>1800</td>\n",
       "      <td>2200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>20000</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>26000</td>\n",
       "      <td>6</td>\n",
       "      <td>1600</td>\n",
       "      <td>2100</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>24000</td>\n",
       "      <td>8</td>\n",
       "      <td>1300</td>\n",
       "      <td>1900</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>27000</td>\n",
       "      <td>5</td>\n",
       "      <td>1700</td>\n",
       "      <td>2300</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I</td>\n",
       "      <td>23000</td>\n",
       "      <td>4</td>\n",
       "      <td>1400</td>\n",
       "      <td>1700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J</td>\n",
       "      <td>29000</td>\n",
       "      <td>2</td>\n",
       "      <td>1900</td>\n",
       "      <td>2400</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  region    gdp unemploy_rate ed_expend health_expend crime_rate\n",
       "0      A  25000             5      1500          2000         10\n",
       "1      B  22000             7      1200          1800         15\n",
       "2      C  28000             4      1800          2200          8\n",
       "3      D  20000             9      1000          1500         20\n",
       "4      E  30000             3      2000          2500          5\n",
       "5      F  26000             6      1600          2100         12\n",
       "6      G  24000             8      1300          1900         18\n",
       "7      H  27000             5      1700          2300          9\n",
       "8      I  23000             4      1400          1700         14\n",
       "9      J  29000             2      1900          2400          7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2331d0-d32f-4c0f-b89e-185326758e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix data type of numeric columns\n",
    "df[['gdp', 'unemploy_rate', 'ed_expend', 'health_expend','crime_rate']] = df[['gdp', 'unemploy_rate', 'ed_expend', 'health_expend','crime_rate']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20cea584-9bf6-425c-bef4-2e9b25430689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   region         10 non-null     object \n",
      " 1   gdp            10 non-null     float64\n",
      " 2   unemploy_rate  10 non-null     float64\n",
      " 3   ed_expend      10 non-null     float64\n",
      " 4   health_expend  10 non-null     float64\n",
      " 5   crime_rate     10 non-null     float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 612.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364fe42-ea84-4afe-8ce1-9a2faa43f807",
   "metadata": {},
   "source": [
    "##### Step 3: Standardizing features (Fix scale of all features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1a06e-1fe0-46a5-85ac-4b4d4eeed5d9",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFE6E6; color:red;padding:5px 5px;margin:0px\">\n",
    "<i>What does mean=0, std=1 actually do?</i><br>\n",
    "<i>How does it affect the assembly of data points?</i><br>\n",
    "[Find out the difference to build visual intuition]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a9f69e2-9417-4d66-8f1d-b32c6785cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(\"region\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29977329-347a-4086-864a-ecb249cde77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize: all features have mean=0, stadard dev=1\n",
    "df2 = (df2 - df2.mean())/df2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6262f7fe-0f2c-4e5f-b32c-ac9a115cf810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp</th>\n",
       "      <th>unemploy_rate</th>\n",
       "      <th>ed_expend</th>\n",
       "      <th>health_expend</th>\n",
       "      <th>crime_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.124838</td>\n",
       "      <td>-0.135526</td>\n",
       "      <td>-0.124838</td>\n",
       "      <td>-0.124838</td>\n",
       "      <td>-0.367764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.061119</td>\n",
       "      <td>0.767982</td>\n",
       "      <td>-1.061119</td>\n",
       "      <td>-0.749025</td>\n",
       "      <td>0.653803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.811444</td>\n",
       "      <td>-0.587280</td>\n",
       "      <td>0.811444</td>\n",
       "      <td>0.499350</td>\n",
       "      <td>-0.776391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.685307</td>\n",
       "      <td>1.671490</td>\n",
       "      <td>-1.685307</td>\n",
       "      <td>-1.685307</td>\n",
       "      <td>1.675370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.435632</td>\n",
       "      <td>-1.039034</td>\n",
       "      <td>1.435632</td>\n",
       "      <td>1.435632</td>\n",
       "      <td>-1.389331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.187256</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.187256</td>\n",
       "      <td>0.187256</td>\n",
       "      <td>0.040863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.436931</td>\n",
       "      <td>1.219736</td>\n",
       "      <td>-0.749025</td>\n",
       "      <td>-0.436931</td>\n",
       "      <td>1.266743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.499350</td>\n",
       "      <td>-0.135526</td>\n",
       "      <td>0.499350</td>\n",
       "      <td>0.811444</td>\n",
       "      <td>-0.572078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.749025</td>\n",
       "      <td>-0.587280</td>\n",
       "      <td>-0.436931</td>\n",
       "      <td>-1.061119</td>\n",
       "      <td>0.449490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.123538</td>\n",
       "      <td>-1.490788</td>\n",
       "      <td>1.123538</td>\n",
       "      <td>1.123538</td>\n",
       "      <td>-0.980704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gdp  unemploy_rate  ed_expend  health_expend  crime_rate\n",
       "0 -0.124838      -0.135526  -0.124838      -0.124838   -0.367764\n",
       "1 -1.061119       0.767982  -1.061119      -0.749025    0.653803\n",
       "2  0.811444      -0.587280   0.811444       0.499350   -0.776391\n",
       "3 -1.685307       1.671490  -1.685307      -1.685307    1.675370\n",
       "4  1.435632      -1.039034   1.435632       1.435632   -1.389331\n",
       "5  0.187256       0.316228   0.187256       0.187256    0.040863\n",
       "6 -0.436931       1.219736  -0.749025      -0.436931    1.266743\n",
       "7  0.499350      -0.135526   0.499350       0.811444   -0.572078\n",
       "8 -0.749025      -0.587280  -0.436931      -1.061119    0.449490\n",
       "9  1.123538      -1.490788   1.123538       1.123538   -0.980704"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
